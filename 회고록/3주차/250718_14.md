# 250714 (금) - 3주차
## 미니 프로젝트

3주 동안 배운 것으로 첫 번째 미니프로젝트를 진행하였다. 
파이썬을 이용해서 페이지를 만들고 streamlit을 사용해서 서비스를 배포할 수 있었다.

깃헙 링크 : https://github.com/YoonjinOh0909/WooriFISA_hyperlocal

데이터를 얻을 수 있는 사이트
- [kaggle](https://www.kaggle.com/datasets)
- [문화 빅데이터 플랫폼](https://www.bigdata-culture.kr/bigdata/user/main.do)
- [공공데이터포털](https://www.data.go.kr/)
- [공공민간데이터](https://www.data1window.kr/)
- [경기데이터](https://data.gg.go.kr/portal/mainPage.do)

### 느낀점 
1. 데이터 선정이 결과에 영향을 끼친다
    - 서울시 가로등 개수라는 제목의 데이터를 사용하여 결과를 도출했지만, 서울시 전체 가로등 개수가 아닌 시에서 관리하는 가로등의 정보만 있었다. 따라서 가로등이 없는 자치구가 있다는 결과가 나옴. 추후 검색을 해보니 자치구에 관리하는 가로등이 별도로 있다는 것을 깨닫고 추가

2. 데이터를 전처리 하는 과정에서 같은 도구를 사용해야한다

    - 각 지역의 ‘동’별 정보를 얻기 위해 외부 api를 사용. 그 과정에서 파이썬의 geopy 라이브러리, 카카오 api 두 가지를 이용. 둘의 결과값이 달라서 데이터를 재처리 
    *예) 종로1 , 2 , 3 , 4 가동 / 종로1.2.3.4가동*

3. 외부 api 혹은 라이브러리를 사용할 때는 종료 시간을 예측하고 실행해야 한다

    - geopy 를 활용해서 위도 경도 값을 얻을 때 colab에서 무작정 실행. 20분이 지나도 끝나지 않자 종료 후 한 개 데이터만 실행해보니 1번의 호출에 0.6-0.7초 소요. 얻어야 하는 데이터의 row가 2만개라 3시간 반 소요가 된다는 것을 인지.
    - 해당 api가 무료로 호출할 때는 느리다는 것을 깨닫고 카카오 api로 변경. colab이 아닌 PC로 실행하니 더욱 빨라져서 1번 호출에 0.04초로 실행되어 데이터를 수월하게 획득
    - 성공, 실패 디버그를 띄우니 진행 정도를 파악할 수 있어서 안정적으로 결과를 기다릴 수 있었음
    - 오랜 실행이 예상될 때는 try-exception 을 통해 오류로 인한 강제종료가 되지 않게 한다.
    - Group by 할 때 agg() 함수를 사용하면 편리하다
    ```변수 =dataframe.groupby('column').column.agg(['mean', 'min', 'max', 'sum'])```

4. 주석을 꼼꼼하게 작성하자
    - 코드를 작성하던 도중 다른 팀원들과 코드를 합치기 위해서 이야기를 하는 중 내가 작성한 코드도 다시 생각해서 설명해야 하는 상황이 발생한다.

### 개선점

자취를 결정할 때 보기 좋은 정보를 제공하기 위한 프로젝트이기 때문에 추가 데이터들이 필요한 것 같다.
범죄 발생율, 지하철 호선 위치 정보를 추가하도록 한다. 회사나 학교가 특정 호선을 통해 접근할 수 있다면, 해당 호선에 쉽게 접근할 수 있는 지역을 추천하도록 한다.

이 프로젝트를 집을 구하기 위한 정보 뿐만 아니라 여행객을 위한 정보로 사용할 수 있을 것이라 예상한다. 유럽 여행을 갈 때 여행객이 지내기 안전한 곳, 피해야 하는 곳 등이 있었다. 한국도 마찬가지로 필요한 정보라 생각이 들어 여행객이 사용할 것이라 생각한다. 
